| **Mnemonic**                              | **What to Recall / Details**                                                                                                                                                                            | **Interview Tip / Trigger / Example**                                                                                                                                       |
| ----------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **S (Synchronous)**                       | - Write is acknowledged **only after all replicas commit** <br> - Guarantees **strong consistency** <br> - Higher write latency, lower availability if a replica fails                                  | - “Use for critical systems like banking, payments” <br> - “Explain tradeoff: strong consistency vs latency & availability” <br> - Example: Galera Cluster for MySQL        |
| **A (Asynchronous)**                      | - Write is acknowledged **immediately by primary**, replicas update later <br> - Eventual consistency <br> - Low write latency, higher availability                                                     | - “High-throughput, logging, analytics, social feeds” <br> - “Mention replication lag and stale reads” <br> - Example: MySQL async replicas, Cassandra async writes         |
| **L (Leader / Primary)**                  | - Single node handles **all writes**, followers replicate <br> - Simple to reason about consistency <br> - Failover required if leader goes down                                                        | - “Classic master-slave setup” <br> - “Discuss failover, leader election, and read scaling via replicas” <br> - Example: PostgreSQL primary with read replicas              |
| **M (Multi-Leader)**                      | - Multiple nodes can accept writes <br> - Conflicts possible → require **resolution strategy** <br> - Higher availability and geo-distribution                                                          | - “Use for multi-region apps” <br> - “Ask: how to resolve conflicts?” <br> - Example: MySQL multi-master, MariaDB multi-leader                                              |
| **Q-C-R (Quorum, Consistency, Replicas)** | - W = write quorum, R = read quorum, N = total replicas <br> - **Rule:** W + R > N ensures read sees latest write <br> - Tune W/R based on latency vs consistency                                       | - “Explain CAP trade-offs” <br> - “Example: Cassandra write W=2, read R=2, N=3 → always overlap → strong consistency” <br> - “Also explain eventual consistency if W+R ≤ N” |
| **TVC (Tombstone, Vector Clock, CRDT)**   | - Conflict resolution methods in **multi-leader / leaderless systems** <br> - Tombstone → deleted markers <br> - Vector Clock → track version history <br> - CRDT → mergeable, conflict-free data types | - “Explain multi-version concurrency” <br> - “Example: Dynamo uses vector clocks, Riak CRDTs” <br> - “Useful when multiple writes occur concurrently”                       |
| **LS (Local / Remote placement)**         | - Local replicas → **low latency reads/writes** <br> - Remote replicas → **disaster recovery / geo-redundancy** <br> - Hybrid strategies balance latency vs durability                                  | - “Design replica placement for SLOs” <br> - “Example: 2 local + 1 cross-region replica in Cassandra” <br> - “Mention tradeoff: cross-region writes increase latency”       |


RCCT framework for storage

replication - Salam ( sync, async, Leaderless, multi-leder, )
COnsistency  - strong, eventual, QUorum
COnfict handling  - TVC 
Trade off LAD( durability vs availabity vs latency
